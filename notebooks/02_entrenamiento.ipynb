{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1e7b7ea",
   "metadata": {},
   "source": [
    "# Entrenamiento baseline\n",
    "Modelo sencillo (ResNet18) que predice Dry_Clover_g, Dry_Green_g y Dry_Dead_g a partir de cada foto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Detectar si estamos en Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    project_path = '/content/drive/MyDrive/image2biomass'\n",
    "    if os.path.exists(project_path):\n",
    "        os.chdir(project_path)\n",
    "        print(f\"Directorio de trabajo cambiado a: {os.getcwd()}\")\n",
    "    else:\n",
    "        print(f\"Advertencia: No se encontr√≥ el directorio {project_path}\")\n",
    "else:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from utils.paths import get_data_path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(get_data_path())\n",
    "train_df = pd.read_csv(base_path / 'train.csv')\n",
    "test_df = pd.read_csv(base_path / 'test.csv')\n",
    "\n",
    "targets = ['Dry_Clover_g', 'Dry_Green_g', 'Dry_Dead_g']\n",
    "pivot = (\n",
    "    train_df\n",
    "    .pivot_table(index='image_path', columns='target_name', values='target')\n",
    "    .reset_index()\n",
    ")\n",
    "pivot = pivot[['image_path'] + targets].dropna().reset_index(drop=True)\n",
    "print(f\"Imagenes disponibles: {len(pivot)}\")\n",
    "pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split simple 80/20\n",
    "perm = np.random.permutation(len(pivot))\n",
    "split = int(len(pivot) * 0.8)\n",
    "train_meta = pivot.iloc[perm[:split]].reset_index(drop=True)\n",
    "val_meta = pivot.iloc[perm[split:]].reset_index(drop=True)\n",
    "\n",
    "img_size = 224\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class BiomassDataset(Dataset):\n",
    "    def __init__(self, df, images_root, transform):\n",
    "        self.df = df\n",
    "        self.images_root = Path(images_root)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.images_root / row['image_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        target = torch.tensor(row[targets].values.astype(np.float32))\n",
    "        return image, target\n",
    "\n",
    "batch_size = 16\n",
    "train_ds = BiomassDataset(train_meta, base_path, train_tfms)\n",
    "val_ds = BiomassDataset(val_meta, base_path, val_tfms)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2125652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(targets))\n",
    "    return model\n",
    "\n",
    "model = create_model().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "epochs = 5\n",
    "best_val = float('inf')\n",
    "\n",
    "def run_epoch(loader, train):\n",
    "    model.train() if train else model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for images, y in loader:\n",
    "            images = images.to(device)\n",
    "            y = y.to(device)\n",
    "            preds = model(images)\n",
    "            loss = criterion(preds, y)\n",
    "            if train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            total_loss += loss.item() * len(images)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = run_epoch(train_loader, train=True)\n",
    "    val_loss = run_epoch(val_loader, train=False)\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        os.makedirs('models', exist_ok=True)\n",
    "        torch.save(model.state_dict(), 'models/baseline_resnet18.pt')\n",
    "    print(f\"Epoch {epoch} | train {train_loss:.4f} | val {val_loss:.4f} | best {best_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ba883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiomassTestDataset(Dataset):\n",
    "    def __init__(self, df, images_root, transform):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.images_root = Path(images_root)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.images_root / row['image_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        return self.transform(image), row['image_path']\n",
    "\n",
    "test_meta = (\n",
    "    test_df[test_df['target_name'].isin(targets)]\n",
    "    .drop_duplicates('image_path')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "test_loader = DataLoader(BiomassTestDataset(test_meta, base_path, val_tfms), batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "model.load_state_dict(torch.load('models/baseline_resnet18.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "pred_rows = []\n",
    "with torch.no_grad():\n",
    "    for images, paths in test_loader:\n",
    "        images = images.to(device)\n",
    "        preds = model(images).cpu().numpy()\n",
    "        for path, pred in zip(paths, preds):\n",
    "            pred_rows.append({\n",
    "                'image_path': path,\n",
    "                **{t: p for t, p in zip(targets, pred)},\n",
    "            })\n",
    "\n",
    "pred_df = pd.DataFrame(pred_rows).sort_values('image_path').reset_index(drop=True)\n",
    "long_df = pred_df.melt(id_vars='image_path', value_vars=targets, var_name='target_name', value_name='target')\n",
    "long_df['sample_id'] = long_df.apply(lambda r: f\"{Path(r['image_path']).stem}__{r['target_name']}\", axis=1)\n",
    "submission = long_df[['sample_id', 'target']]\n",
    "os.makedirs('models', exist_ok=True)\n",
    "submission.to_csv('models/submission_baseline.csv', index=False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
