{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1e7b7ea",
   "metadata": {},
   "source": [
    "# Entrenamiento baseline\n",
    "Modelo sencillo (ResNet18) que predice Dry_Clover_g, Dry_Green_g y Dry_Dead_g a partir de cada foto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Detectar si estamos en Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    project_path = '/content/drive/MyDrive/image2biomass'\n",
    "    if os.path.exists(project_path):\n",
    "        os.chdir(project_path)\n",
    "        print(f\"Directorio de trabajo cambiado a: {os.getcwd()}\")\n",
    "    else:\n",
    "        print(f\"Advertencia: No se encontró el directorio {project_path}\")\n",
    "    !pip install mlflow\n",
    "else:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from utils.paths import get_data_path\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from src.utils.seed import set_seed\n",
    "from src.utils.config import TrainingConfig\n",
    "from src.utils.metrics import DEFAULT_TARGET_WEIGHTS, weighted_r2_score\n",
    "from src.data.dataloader import make_dataloaders\n",
    "from src.models.resnet import create_resnet\n",
    "from src.training.trainer import Trainer\n",
    "from src.inference.predictor import Predictor\n",
    "\n",
    "SEED = 42\n",
    "cfg = TrainingConfig()\n",
    "set_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e82bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar MLflow\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"https://abcd-12-34-56.ngrok-free.app\"\n",
    "os.environ[\"MLFLOW_TRACKING_INSECURE_TLS\"] = \"true\"  # importante para ngrok\n",
    "mlflow.set_experiment(\"biomass_prediction\")\n",
    "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(get_data_path())\n",
    "train_df = pd.read_csv(base_path / 'train.csv')\n",
    "test_df = pd.read_csv(base_path / 'test.csv')\n",
    "\n",
    "targets = ['Dry_Clover_g', 'Dry_Green_g', 'Dry_Dead_g']\n",
    "pivot = (\n",
    "    train_df\n",
    "    .pivot_table(index='image_path', columns='target_name', values='target')\n",
    "    .reset_index()\n",
    ")\n",
    "pivot = pivot[['image_path'] + targets].dropna().reset_index(drop=True)\n",
    "print(f\"Imagenes disponibles: {len(pivot)}\")\n",
    "pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split simple 80/20\n",
    "perm = np.random.permutation(len(pivot))\n",
    "split = int(len(pivot) * 0.8)\n",
    "train_meta = pivot.iloc[perm[:split]].reset_index(drop=True)\n",
    "val_meta = pivot.iloc[perm[split:]].reset_index(drop=True)\n",
    "\n",
    "train_loader, val_loader, val_tfms = make_dataloaders(\n",
    "    train_meta,\n",
    "    val_meta,\n",
    "    targets=targets,\n",
    "    images_root=base_path,\n",
    "    img_size=cfg.img_size,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.num_workers,\n",
    "    )\n",
    "len(train_meta), len(val_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2125652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar experimento MLflow\n",
    "with mlflow.start_run(run_name=\"resnet18_baseline_frozen\"):\n",
    "    # Log de hiperparámetros\n",
    "    mlflow.log_params({\n",
    "        \"model\": \"ResNet18\",\n",
    "        \"img_size\": cfg.img_size,\n",
    "        \"batch_size\": cfg.batch_size,\n",
    "        \"lr\": cfg.lr,\n",
    "        \"epochs\": cfg.epochs,\n",
    "        \"early_stopping_patience\": cfg.early_stopping_patience,\n",
    "        \"freeze_backbone\": cfg.freeze_backbone,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"loss\": \"MSE\",\n",
    "        \"seed\": SEED,\n",
    "        \"num_train_samples\": len(train_meta),\n",
    "        \"num_val_samples\": len(val_meta)\n",
    "    })\n",
    "    \n",
    "    # Crear modelo con backbone congelado\n",
    "    model = create_resnet(len(targets), freeze_backbone=cfg.freeze_backbone).to(device)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "    \n",
    "    # Log del número de parámetros entrenables\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    mlflow.log_params({\n",
    "        \"trainable_params\": trainable_params,\n",
    "        \"total_params\": total_params,\n",
    "        \"trainable_ratio\": f\"{trainable_params/total_params:.4f}\"\n",
    "    })\n",
    "    print(f\"Parámetros entrenables: {trainable_params:,} / {total_params:,} ({trainable_params/total_params:.2%})\")\n",
    "    \n",
    "    # Entrenamiento\n",
    "    trainer = Trainer(model, criterion, optimizer, device)\n",
    "    history = trainer.fit(\n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        epochs=cfg.epochs, \n",
    "        checkpoint_path=cfg.checkpoint_path,\n",
    "        early_stopping_patience=cfg.early_stopping_patience\n",
    "    )\n",
    "    \n",
    "    # Log de métricas por época\n",
    "    for record in history:\n",
    "        mlflow.log_metrics({\n",
    "            \"train_loss\": record[\"train_loss\"],\n",
    "            \"val_loss\": record[\"val_loss\"],\n",
    "            \"best_val_loss\": record[\"best_val\"],\n",
    "        }, step=record[\"epoch\"])\n",
    "    \n",
    "    # Cargar el mejor modelo\n",
    "    model.load_state_dict(torch.load(cfg.checkpoint_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    # Log del modelo en MLflow\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n",
    "    \n",
    "    # Curvas de entrenamiento\n",
    "    history_df = pd.DataFrame(history)\n",
    "    plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    ax.plot(history_df[\"epoch\"], history_df[\"train_loss\"], marker=\"o\", label=\"Train loss\")\n",
    "    ax.plot(history_df[\"epoch\"], history_df[\"val_loss\"], marker=\"o\", label=\"Val loss\")\n",
    "    ax.set_xlabel(\"Época\")\n",
    "    ax.set_ylabel(\"MSE\")\n",
    "    ax.set_title(\"Evolución de la pérdida\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Guardar gráfica en MLflow\n",
    "    mlflow.log_figure(fig, \"training_loss_curve.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Métrica ponderada y dispersión de validación\n",
    "    y_true, y_pred, name_labels = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets_batch in val_loader:\n",
    "            images = images.to(device)\n",
    "            preds = model(images).cpu().numpy()\n",
    "            targets_np = targets_batch.numpy()\n",
    "            batch_size = targets_np.shape[0]\n",
    "            y_true.append(targets_np.reshape(-1))\n",
    "            y_pred.append(preds.reshape(-1))\n",
    "            name_labels.append(np.tile(np.array(targets), batch_size))\n",
    "\n",
    "    y_true_flat = np.concatenate(y_true)\n",
    "    y_pred_flat = np.concatenate(y_pred)\n",
    "    name_labels_flat = np.concatenate(name_labels)\n",
    "\n",
    "    # Calcular métricas globales\n",
    "    val_weighted_r2 = weighted_r2_score(\n",
    "        y_true=y_true_flat,\n",
    "        y_pred=y_pred_flat,\n",
    "        target_names=name_labels_flat,\n",
    "        target_weights=DEFAULT_TARGET_WEIGHTS,\n",
    "    )\n",
    "    \n",
    "    global_mae = mean_absolute_error(y_true_flat, y_pred_flat)\n",
    "    global_rmse = np.sqrt(mean_squared_error(y_true_flat, y_pred_flat))\n",
    "    global_r2 = r2_score(y_true_flat, y_pred_flat)\n",
    "    \n",
    "    print(f\"\\n=== Métricas globales de validación ===\")\n",
    "    print(f\"R² ponderado: {val_weighted_r2:.4f}\")\n",
    "    print(f\"MAE: {global_mae:.4f}\")\n",
    "    print(f\"RMSE: {global_rmse:.4f}\")\n",
    "    print(f\"R²: {global_r2:.4f}\")\n",
    "    \n",
    "    # Log de métricas globales\n",
    "    mlflow.log_metrics({\n",
    "        \"val_weighted_r2\": val_weighted_r2,\n",
    "        \"val_mae\": global_mae,\n",
    "        \"val_rmse\": global_rmse,\n",
    "        \"val_r2\": global_r2\n",
    "    })\n",
    "    \n",
    "    # Calcular métricas por target\n",
    "    print(f\"\\n=== Métricas por target ===\")\n",
    "    for target_name in targets:\n",
    "        mask = name_labels_flat == target_name\n",
    "        y_true_target = y_true_flat[mask]\n",
    "        y_pred_target = y_pred_flat[mask]\n",
    "        \n",
    "        mae = mean_absolute_error(y_true_target, y_pred_target)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true_target, y_pred_target))\n",
    "        r2 = r2_score(y_true_target, y_pred_target)\n",
    "        \n",
    "        print(f\"{target_name}: MAE={mae:.4f}, RMSE={rmse:.4f}, R²={r2:.4f}\")\n",
    "        \n",
    "        # Log métricas por target\n",
    "        mlflow.log_metrics({\n",
    "            f\"{target_name}_mae\": mae,\n",
    "            f\"{target_name}_rmse\": rmse,\n",
    "            f\"{target_name}_r2\": r2\n",
    "        })\n",
    "\n",
    "    # Gráfico de dispersión\n",
    "    fig, axes = plt.subplots(1, len(targets), figsize=(4 * len(targets), 4), sharex=False, sharey=False)\n",
    "    for idx, target_name in enumerate(targets):\n",
    "        mask = name_labels_flat == target_name\n",
    "        y_true_target = y_true_flat[mask]\n",
    "        y_pred_target = y_pred_flat[mask]\n",
    "        \n",
    "        ax = axes[idx] if len(targets) > 1 else axes\n",
    "        ax.scatter(y_true_target, y_pred_target, alpha=0.5, s=14, label=\"Pred vs GT\")\n",
    "        min_val = min(y_true_target.min(), y_pred_target.min())\n",
    "        max_val = max(y_true_target.max(), y_pred_target.max())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], color=\"tab:red\", linewidth=1, label=\"Ideal\")\n",
    "        \n",
    "        # Calcular R² para el título\n",
    "        r2 = r2_score(y_true_target, y_pred_target)\n",
    "        ax.set_title(f\"{target_name}\\nR²={r2:.3f}\")\n",
    "        ax.set_xlabel(\"Ground truth\")\n",
    "        ax.set_ylabel(\"Predicción\")\n",
    "        ax.legend()\n",
    "        \n",
    "    fig.suptitle(\"Dispersión predicciones vs verdad en validación\", y=1.02, fontsize=12)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Guardar gráfica en MLflow\n",
    "    mlflow.log_figure(fig, \"validation_scatter_plots.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Predicciones y submission\n",
    "    predictor = Predictor(model, device)\n",
    "    submission = predictor.predict(\n",
    "        test_df,\n",
    "        targets,\n",
    "        images_root=base_path,\n",
    "        transform=val_tfms,\n",
    "        batch_size=cfg.batch_size,\n",
    "        num_workers=cfg.num_workers,\n",
    "    )\n",
    "    os.makedirs(cfg.model_dir, exist_ok=True)\n",
    "    submission.to_csv(cfg.model_dir / 'submission_baseline.csv', index=False)\n",
    "    \n",
    "    # Log del archivo de submission\n",
    "    mlflow.log_artifact(str(cfg.model_dir / 'submission_baseline.csv'), \"submission\")\n",
    "    \n",
    "    print(f\"\\n=== Experimento completado ===\")\n",
    "    print(f\"Run ID: {mlflow.active_run().info.run_id}\")\n",
    "    print(f\"Submission guardado en: {cfg.model_dir / 'submission_baseline.csv'}\")\n",
    "\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
