{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1e7b7ea",
   "metadata": {},
   "source": [
    "# Entrenamiento baseline\n",
    "Modelo sencillo (ResNet18) que predice Dry_Clover_g, Dry_Green_g y Dry_Dead_g a partir de cada foto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Detectar si estamos en Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    project_path = '/content/drive/MyDrive/image2biomass'\n",
    "    if os.path.exists(project_path):\n",
    "        os.chdir(project_path)\n",
    "        print(f\"Directorio de trabajo cambiado a: {os.getcwd()}\")\n",
    "    else:\n",
    "        print(f\"Advertencia: No se encontr√≥ el directorio {project_path}\")\n",
    "else:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from utils.paths import get_data_path\n",
    "\n",
    "import torch\n",
    "\n",
    "from src.utils.seed import set_seed\n",
    "from src.utils.config import TrainingConfig\n",
    "from src.data.dataloader import make_dataloaders\n",
    "from src.models.resnet import create_resnet\n",
    "from src.training.trainer import Trainer\n",
    "from src.inference.predictor import Predictor\n",
    "\n",
    "SEED = 42\n",
    "cfg = TrainingConfig()\n",
    "set_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(get_data_path())\n",
    "train_df = pd.read_csv(base_path / 'train.csv')\n",
    "test_df = pd.read_csv(base_path / 'test.csv')\n",
    "\n",
    "targets = ['Dry_Clover_g', 'Dry_Green_g', 'Dry_Dead_g']\n",
    "pivot = (\n",
    "    train_df\n",
    "    .pivot_table(index='image_path', columns='target_name', values='target')\n",
    "    .reset_index()\n",
    ")\n",
    "pivot = pivot[['image_path'] + targets].dropna().reset_index(drop=True)\n",
    "print(f\"Imagenes disponibles: {len(pivot)}\")\n",
    "pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split simple 80/20\n",
    "perm = np.random.permutation(len(pivot))\n",
    "split = int(len(pivot) * 0.8)\n",
    "train_meta = pivot.iloc[perm[:split]].reset_index(drop=True)\n",
    "val_meta = pivot.iloc[perm[split:]].reset_index(drop=True)\n",
    "\n",
    "train_loader, val_loader, val_tfms = make_dataloaders(\n",
    "    train_meta,\n",
    "    val_meta,\n",
    "    targets=targets,\n",
    "    images_root=base_path,\n",
    "    img_size=cfg.img_size,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.num_workers,\n",
    "    )\n",
    "len(train_meta), len(val_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2125652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_resnet(len(targets)).to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "\n",
    "trainer = Trainer(model, criterion, optimizer, device)\n",
    "history = trainer.fit(train_loader, val_loader, epochs=cfg.epochs, checkpoint_path=cfg.checkpoint_path)\n",
    "\n",
    "model.load_state_dict(torch.load(cfg.checkpoint_path, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ba883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(model, device)\n",
    "submission = predictor.predict(\n",
    "    test_df,\n",
    "    targets,\n",
    "    images_root=base_path,\n",
    "    transform=val_tfms,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=cfg.num_workers,\n",
    " )\n",
    "os.makedirs(cfg.model_dir, exist_ok=True)\n",
    "submission.to_csv(cfg.model_dir / 'submission_baseline.csv', index=False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
